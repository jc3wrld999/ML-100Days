{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6db56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import urllib.request\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84e1be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\",\n",
    "    filename=\"ChatBotData.csv\",\n",
    ")\n",
    "Chatbot_Data = pd.read_csv(\"ChatBotData.csv\")\n",
    "\n",
    "# Test 용으로 300개 데이터만 처리한다.\n",
    "Chatbot_Data = Chatbot_Data[:300]\n",
    "Chatbot_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7efebce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837a68a5b0484d2eb823d858c838031e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.83M [00:02<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b83911ea1145b9ac3fc0a585fad255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "BOS = \"</s>\"\n",
    "EOS = \"</s>\"\n",
    "PAD = \"<pad>\"\n",
    "MASK = \"<unused0>\"\n",
    "\n",
    "# 허깅페이스 transformers 에 등록된 사전 학습된 koGTP2 토크나이저를 가져온다.\n",
    "koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token=BOS, eos_token=EOS, unk_token=\"<unk>\", pad_token=PAD, mask_token=MASK,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c598b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 데이터를 처리하는 클래스를 만든다.\n",
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, chats, max_len=40):  # 데이터셋의 전처리를 해주는 부분\n",
    "        self._data = chats\n",
    "        self.max_len = max_len\n",
    "        self.q_token = Q_TKN\n",
    "        self.a_token = A_TKN\n",
    "        self.sent_token = SENT\n",
    "        self.eos = EOS\n",
    "        self.mask = MASK\n",
    "        self.tokenizer = koGPT2_TOKENIZER\n",
    "\n",
    "    def __len__(self):  # chatbotdata 의 길이를 리턴한다.\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, idx):  # 로드한 챗봇 데이터를 차례차례 DataLoader로 넘겨주는 메서드\n",
    "        turn = self._data.iloc[idx]\n",
    "        q = turn[\"Q\"]  # 질문을 가져온다.\n",
    "        q = re.sub(r\"([?.!,])\", r\" \", q)  # 구둣점들을 제거한다.\n",
    "\n",
    "        a = turn[\"A\"]  # 답변을 가져온다.\n",
    "        a = re.sub(r\"([?.!,])\", r\" \", a)  # 구둣점들을 제거한다.\n",
    "\n",
    "        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n",
    "        q_len = len(q_toked)\n",
    "\n",
    "        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n",
    "        a_len = len(a_toked)\n",
    "\n",
    "        #질문의 길이가 최대길이보다 크면\n",
    "        if q_len > self.max_len:\n",
    "            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\n",
    "            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\n",
    "                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로 \n",
    "                q_len = len(q_toked)\n",
    "                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\n",
    "            a_toked = a_toked[:a_len]\n",
    "            a_len = len(a_toked)\n",
    "\n",
    "        #질문의 길이 + 답변의 길이가 최대길이보다 크면\n",
    "        if q_len + a_len > self.max_len:\n",
    "            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\n",
    "            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\n",
    "                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로 \n",
    "                q_len = len(q_toked)\n",
    "                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\n",
    "            a_toked = a_toked[:a_len]\n",
    "            a_len = len(a_toked)\n",
    "\n",
    "        # 답변 labels = [mask, mask, ...., mask, ..., <bos>,..답변.. <eos>, <pad>....]\n",
    "        labels = [self.mask,] * q_len + a_toked[1:]\n",
    "\n",
    "        # mask = 질문길이 0 + 답변길이 1 + 나머지 0\n",
    "        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n",
    "        # 답변 labels을 index 로 만든다.\n",
    "        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n",
    "        # 최대길이만큼 PADDING\n",
    "        while len(labels_ids) < self.max_len:\n",
    "            labels_ids += [self.tokenizer.pad_token_id]\n",
    "\n",
    "        # 질문 + 답변을 index 로 만든다.    \n",
    "        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n",
    "        # 최대길이만큼 PADDING\n",
    "        while len(token_ids) < self.max_len:\n",
    "            token_ids += [self.tokenizer.pad_token_id]\n",
    "\n",
    "        #질문+답변, 마스크, 답변\n",
    "        return (token_ids, np.array(mask), labels_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93384a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    mask = [item[1] for item in batch]\n",
    "    label = [item[2] for item in batch]\n",
    "    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5758025",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Q_TKN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_set \u001b[38;5;241m=\u001b[39m \u001b[43mChatbotDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mChatbot_Data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#윈도우 환경에서 num_workers 는 무조건 0으로 지정, 리눅스에서는 2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_set, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_batch,)\n",
      "Cell \u001b[1;32mIn [6], line 6\u001b[0m, in \u001b[0;36mChatbotDataset.__init__\u001b[1;34m(self, chats, max_len)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m chats\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_len \u001b[38;5;241m=\u001b[39m max_len\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_token \u001b[38;5;241m=\u001b[39m \u001b[43mQ_TKN\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma_token \u001b[38;5;241m=\u001b[39m A_TKN\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msent_token \u001b[38;5;241m=\u001b[39m SENT\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Q_TKN' is not defined"
     ]
    }
   ],
   "source": [
    "train_set = ChatbotDataset(Chatbot_Data, max_len=40)\n",
    "\n",
    "#윈도우 환경에서 num_workers 는 무조건 0으로 지정, 리눅스에서는 2\n",
    "train_dataloader = DataLoader(train_set, batch_size=32, num_workers=0, shuffle=True, collate_fn=collate_batch,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
